{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "# Time series is still not \"solved\"\n",
    "\n",
    "On the most \"ubiquitously cited\" tasks, as image classification, with the advent of Deep Learning, we see steady progress.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1oloHhvznr2jpx5XwBieCCbI9FyLIl_nK\" width=65%>\n",
    "\n",
    "\n",
    "[source](https://www.researchgate.net/publication/356083410_A_Survey_on_Green_Deep_Learning)\n",
    "\n",
    "On the other hand, from business perspective more prevalent task of time series forecasting receives comparatively less attention and progress is definitely more difficult to follow. This comes partly from the fact, that the variety of time series is presumably large, in many cases solving one forecasting problem has nothing to say about another one (or one might think so - and we will argue otherwise), and partly from the fact, that the most prestiguous benchmar in the field, the [M competition](https://forecasters.org/resources/time-series-data/) is organized more rarely and it's successive installments do not really lend themselves to easy comparison.\n",
    "\n",
    "That seaid, the introduction of RNN/LSTM models represented a step in the time series prediction domain. None the less, the need for advancements in multiple areas remained, since models could be enhanced with respect to:\n",
    "\n",
    "- interpretability\n",
    "- confidence intervals (see eg.: [DeepAR](https://arxiv.org/abs/1704.04110))\n",
    "- multi step forecasting\n",
    "- __better accuracy__ and most importantly\n",
    "- __transfer learning__\n",
    "\n",
    "In our current discussion, we mainly focus on this latter two points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "## Competitive results\n",
    "\n",
    "Even though RNN/LSTM based models could produce strong results in certain domains of time series modeling, and came with the added benefit of deep representations (like handling of different length timeseries, seq2seq scenarios, fixed length representation abilities and __potential transferability__), their __practical performance was often case not dominantly better than classical__, eg. autoregressive models, especially eg. Facebook's [Prophet](https://facebook.github.io/prophet/) or even [ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average).\n",
    "\n",
    "The main \"measuring rod\" for model performance in time series modeling, the [M4 competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128) showed, that hybrid approaches __combining classical models with LSTMs__ can be pretty competitive solutions, so the next era can be described by these kind of approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "## An example of hybrid models: ES-LSTM\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1YHhnPMLvLdRMZCTgADbO_zlXWdFVx0w6\"><img src=\"https://drive.google.com/uc?export=view&id=1OSM9XKUAw10hj-STVKBYfF4Zbyw10MzC\" width=55%></a>\n",
    "\n",
    "Source: [M4 Forecasting Competition: Introducing a New Hybrid ES-RNN Model](https://eng.uber.com/m4-forecasting-competition/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "Though there are many technicalities worth studying in detail, the main intuition behind this model is to replace the linear trend assumption in the Holt-Winters Exponential Smoothing model to accommodate more complex, \"non linear trend\" in the form of LSTMs, and keeping the ability of ES models to describe the \"level\" and \"seasonal\" components in the traditional way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "There is also a newer, multivariate extension of ES-RNN calles [MES-RNN](https://arxiv.org/abs/2112.08618) available.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Oi0vbv4_G96Vy3LetxdgFWmFZcg8Em2A\" width=65%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "# Do transformers come to time series?\n",
    "\n",
    "We already know, that attention based architectures, \"transformers\" caused a revolution in the NLP domain, and are increasingly present also in the computer vision domain (eg. in form of [hybrid attention / convolution solutions](https://arxiv.org/abs/2106.04803), representing the state of the art on imagenet as of September 2021). The question naturally arises, if transformers can be of benefit also in the time series domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "## Potential benefits\n",
    "\n",
    "Isaac Godfried summarizes the potential benefits of transformers in the time series domain in his [short talk](https://www.youtube.com/watch?v=zteRgsiWcxI&t=225s) quite nicely:\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1IHH9b4dZlJonuYN1_7OElWYRH_Mzia97\"><img src=\"https://drive.google.com/uc?export=view&id=19n538WWN0ionGDYYBb8z4ZDpLBlzdIpw\" width=45%></a>\n",
    "\n",
    "Also worth mentioning, that the potential performance enhancements in large scale training are also promising. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "## Theoretical motivation\n",
    "\n",
    "As a theoretical motivation for the possible extra performance of the attention based models comes from the fact, that they offer a different paradigm for discovering the temporal relationships between different points in the timeseries, namely:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "- __Convolutions__ are presupposing, that there is a kind of __local relationship__ between the time points (which can be made more proper with \"causal convolutions\" and more wide with \"dilated convolutions\"), none the less, the basic assumption remains fairly local.\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/deepmind-live-cms/documents/BlogPost-Fig2-Anim-160908-r01.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1VadvwmhZ1--Wx6O1JR2G30anydCdk-mc\" width=45%></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "- __RNN/LSTM models__ though have the potential for long term memory, but have the drawback not just of __sequential computation__ but also tha __challenge of \"dragging the information\" through many timesteps__. There is no easy possibility for an LSTM to pay direct, local attention to a distant timestep by \"jumping over\" all the steps inbetween.\n",
    "\n",
    "<a href=\"https://static.wixstatic.com/media/3eee0b_969c1d3e8d7943f0bd693d6151199f69~mv2.gif\"><img src=\"https://drive.google.com/uc?export=view&id=1Np87UUp-5YD_34LyG0Z-sO-OyCShaDcv\" width=45%></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "The attention based solutions promise to enable just that: the possibility to attend to any point in time (inside the processing window, that is), diractly and parallelizably.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1xM_y7bGSQ7YkT7kFgev26fwuShWb0fVO\" width=65%>\n",
    "\n",
    "[source](https://paperswithcode.com/paper/self-attention-for-raw-optical-satellite-time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "## Why not just slap a transformer on it?\n",
    "\n",
    "Though it may sound very tempting to just take an \"out of the box\" implementation of transformers and apply it to a given time series, there are multiple drawbacks that have to be addressed before one can expect good results.\n",
    "\n",
    "As outlined in the paper [Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting](https://arxiv.org/abs/1907.00235) there are potentially two main drawbacks for \"vanila\" transformers in TS omain that have to be mitigated:\n",
    "\n",
    "1. Locality insensitivity\n",
    "2. Quadratic dependence bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "### Locality insensitivity problem\n",
    "\n",
    "It is important to observe, that even in case of NLP transformers, the attention mechanisms were completely position agnostic, hence additional information had to be supplied ti the model to \"mark\" the position of given elements in a sequence. In the NLP case some [positional encoding](https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3) had to be utilized in the form of multiplication with the input embeddings.\n",
    "\n",
    "<a href=\"https://www.researchgate.net/publication/327068570/figure/fig3/AS:660457148928000@1534476663109/The-original-positional-encoding-used-in-Attention-Is-All-You-Need-VSP-17-composed.png\"><img src=\"https://drive.google.com/uc?export=view&id=13PZAH1REUi3hImSY6O-8RYoQf8PYlKco\" width=45%></a>\n",
    "\n",
    "Notably, the inputs in the case of NLP were complex embedding vectors themselves, but in case of time series, they are typically just scalars (per input time series, which in case of multivariate modeling naturally forms vectors), which are by no means embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "One of the avenues one can take here is to utilize some form of sinusoidal [time encoding](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/). Though not totally clear that only adding these encodings as additional features (as if they were additional time series inputs for the models) is sufficient, and also if how their exact periodicity should be set up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "Fort he latter problem, something like [time2vec](https://arxiv.org/abs/1907.05321) embedding, that are learnable time encodings can be of service.\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1SgFlwYAYbdYweSNb4T08-DbVO1_vljmK\"><img src=\"https://drive.google.com/uc?export=view&id=1UUchz4WivadH4aFiwmK-UX1DdUgcU2VW\" width=30%></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "In case of the [\"Enhancing locality...\"](https://arxiv.org/abs/1907.00235) paper they give a different interpretation of the locality problem, namely: they would like to enhance the model's ability to incorporate information from the sorrounding timepoints, or more specifically the recent past of a given timestep during the generation of query and key vectors in attention. They achieve this by introducing some locality assumptions in form of causal convolutions. More on this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "### Quadratic dependence problem\n",
    "\n",
    "In it's basic form, self attention is having a __quadratic complexity with respect to sequence length__, that is, if the input sequence becomes large enough, the application of classical attention layers becomes simple infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "The proposed solution of the authors is [LogSparse Transformer](https://arxiv.org/abs/1907.00235), which is basically a strategy to balance the need for a wide enough input window and a reasonable amount of computation. The paper achieves it by a kind of sampling strategy, in which the immediate past for the current prediction horizon is accessible in it's completeness, and the more distant past is subsampled in tricky ways to keep the balance.\n",
    "\n",
    "<a href=\"https://user-images.githubusercontent.com/42165262/75024151-50998c80-54dc-11ea-911d-8405b00bb8a7.png\"><img src=\"https://drive.google.com/uc?export=view&id=1eIxZ49q7My0fL-4elIDdVFjUj5o3m3IU\" width=65%></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T07:09:49.993525Z",
     "start_time": "2021-09-26T07:09:49.957577Z"
    }
   },
   "source": [
    "## Is this the end?\n",
    "\n",
    "Certainly not. Hybridization, as observed already in case of computer vision continues in the TS domain, namely a convolutional - attentional hybrid approach has been proposed in the work [Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting](https://arxiv.org/abs/1907.00235).\n",
    "\n",
    "<a href=\"https://miro.medium.com/max/1214/1*YBbULIOPnECwvW7fy9NK7A.png\"><img src=\"https://drive.google.com/uc?export=view&id=1TAP366xiVO54xYFt7uTmXkkE6i9gfUab\" width=45%></a>\n",
    "\n",
    "\"We propose convolutional self attention mechanism by employing causal convolutions to produce queries and keys in the self attention layer. Query-key matching aware of local context, e.g. shapes, can help the model achieve lower training error and further improve its forecasting accuracy.\"\n",
    "\n",
    "It can be assumed, that further hybrid models will appear.\n",
    "\n",
    "More details and overview can be found [here](https://towardsdatascience.com/attention-for-time-series-classification-and-forecasting-261723e0006d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full connections strike back end-to-end!\n",
    "\n",
    "Though one of the important trends pointed out by the M4 competition (and Makridakis himself, the \"M\" in the competition's name) was the hybridization of deep learning and classical tools, followed by other tries to bring the transformer revolution to the field, some \"rebels\" opted to design a generic, end-to-end, time series specific arhitecture with no classical models or attention blocks involved.\n",
    "\n",
    "The paper [\"N-BEATS: Neural basis expansion analysis for interpretable time series forecasting\"](https://arxiv.org/abs/1905.10437) proposes an architecture\n",
    "- inspired by classical time series decomposition techniques\n",
    "- containing only fully connected layers (with traditional linear or ReLU activations)\n",
    "- potentially having interpretability enhancing modifications\n",
    "- having generally high performance \n",
    "\n",
    "For this discussion we follow the lead of [this](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb) excellent reproduction of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General architecture:\n",
    "\n",
    "The general structure of the full architecture is as follows:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1SaasyDMrv5rmeaQFEXsG-pT-dVPoUHWc\" width=55%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The setup\n",
    "\n",
    "From the data perspective, the general setup is pretty traditional: we take an input window worth of historic data, and we are trying to predict a forward looking horizon.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1mhsSq4qR8--FCXP3XcNQ5kwSuOk2XK7_\" width=45%>\n",
    "\n",
    "Please observe, that the optput can not just be a single point in time, but it can be a vector representing arbitrary many timepoints into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Block\n",
    "\n",
    "The difference in approach from previous solutions is, that the smallest unit of the whole architecture, the \"block\" is not just trying to generate a prediction about the future horizon __\"forecast\"__, but also some estimation / representation of the input window itself, a so called __\"backcast\"__. \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1_YPSYvSG5xAELUSX4B2qgvR1OM_qwLo3\" width=20%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is achieved by having some (in the main implementation 4) __fully connected neural layers__ (originally with ReLU activations) generating some \"theta\" parameter layer, which is then used in two ways: \n",
    "1. One linear activation FC layer projects the layer's output to become the \"forecast\"\n",
    "2. Another, independent FC layer does the projection for the \"backcast\"\n",
    "\n",
    "This is so far nearly standard. The real gist of the solution lies in the usage of these blocks in \"stacks\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The stack\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1HyvlrWBTsiIOgV86IE6B3DsJRuycQjI6\" width=20%>\n",
    "\n",
    "As demonstrated on the image above, the individual predictions, so the \"forecasts\" and \"backcasts\" from the blocks are handled differently.\n",
    "\n",
    "1. The role of the forecast is to __additively__ contribute to the full stack forecast (as in: adding together tome series components, like trend, seasonality, patterns,...)\n",
    "2. The role of the \"backcast\" is to __substractively__ remove the given components (trends, seasonalities, patterns,. etc.) from the input for a next layer of blocks.\n",
    "\n",
    "This can be considered the first kind of \"residual network\" behavior of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi stack\n",
    "\n",
    "Finally, the layering of stacks - on the input side, doing residual substraction, on the forecast side doing cumulative addition -  completes the whole model.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1brqZOsGKk0GsATvycIIXBBjd2eyCA0_c\" width=20%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added tricks\n",
    "\n",
    "- Ensambling: For the final performance on competition data, unsurprisingly an ensamble of NBEATS models is created. This has dual purpose:\n",
    "    - Better accuracy\n",
    "    - Potential to easily do some confidence estimates based on a distribution of model outputs\n",
    "- Replacing the activation function of certain blocks to trend detecting (linear) and season detecting (sinusoidal) activations, thus enhancing model interpretability in the original spirit of time series decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A variant for longer horizons: N-HiTS\n",
    "\n",
    "Thöough very similar in the general concept, a new variant of N-BEATS named [N-HiTS](https://arxiv.org/pdf/2201.12886.pdf) emerged recently as a refinement and adaptation especially for long horizon forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general picture is basically the same.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1peT8L_rVkrHXzcDLb_THFbHWbOHogX3u\" width=65%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there are two specific differences worth noting:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=120qabPkKsq_XWhQ3fku6SJF7DYmt3RQi\" width=15%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The addition of a $MaxPool$ layer into the blocks, that in the words of the authors:\n",
    "\n",
    "\"At the input to each block ℓ, we propose to use a MaxPool layer with kernel size $k_{ℓ}$ to help it focus on analyzing compo- nents of its input with a specific scale. Larger $k_{ℓ}$ will tend to cut more high-frequency/small-time-scale components from the input of the MLP, forcing the block to focus on analyzing large scale/low frequency content. We call this multi-rate signal sampling, referring to the fact that the MLP in each block faces a different effective input signal sampling rate. Intuitively, this helps the blocks with larger pooling kernel size $k_{ℓ}$ focus on analyzing large scale components critical for producing consistent long-horizon forecasts.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Addition of an interpolation mechanism in the generation of fore and backcasts, that serves as a performance enhancer, since it enables the model to keep the number of parameters reasonably low even in the case of a longer term forecast. Contrast this to the fact that Transformers in their default case scale quadratically with respect to input lengts, but even the advanced versions of them, as well as the N-BEATS model is constrained by needing as many output nodes as timesteps in the forecast. The interpolation method in N-HiTS effectively mitigates that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This - beyond the pure computational advantages - offers benefits in the smoothness, thus, the robustness of predictions:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=10Dl4tqWySHLa4juwa3AbAr_wVWmrr9Gs\" width=45%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of architectural approaches\n",
    "\n",
    "With considerable amount of handwaving, one can argue, that even in case of the newly proposed neural architectures, some classical intuitions remain, thus one can in a sense treat the big approaches to neural model building as \"analogons\" of the \"good old\" techniques in the sense, that they represent specific inductive biases capitalizing on one or the other properties of time series.\n",
    "\n",
    "| Intuition  |  Non-neural model class |  Neural \"analogue\" examples|\n",
    "|---|---|---|\n",
    "|  Local/neighbouring influence / short term memory | Wavelets  | ConvNet / TCN  |   \n",
    "|  Cumulativity / smoothing / longer term \"blurry\" influence | ExponentialSmoothing   | LSTM variants |   \n",
    "|  Pointwise distant influence |  tree based regression models  | Attention / Transformer |   \n",
    "|  Composability from (continuous) \"shapes\" |  \"decomposition methods\"  |  N-BEATS/HiTS |   \n",
    "\n",
    "\n",
    "There are also bodies of work in applying explicit Fourier transform based neural methods see eg. [here](https://arxiv.org/pdf/2109.13090.pdf) and ordinary differential equation based neural models see eg. [here](https://arxiv.org/pdf/2010.00951.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning in time series\n",
    "\n",
    "Generally, one could reasonably argue, that the main innovation of Deep Learning is the representation ability of the models, that learns useful \"embeddings\" of the data over and beyond the strict confines of a given dataset, or even a given domain. It is by no surprise, that Ian Goodfellow in his famouis venn diagram puts Deep Learing squarely into the representation learning category.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Z8p7XZZTV3zOIsYlmLrggoAs0Ach_hDt\" width=35%>\n",
    "\n",
    "In case of visual, audio and NLP tasks the dominance of transfer learning - that is, the pre-training on large scale domain independent data, then finetuning (or even just \"prompt engineering\") the model is asolute. It is arguably the essence of the success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how about transfer learning in time series?\n",
    "\n",
    "Though we could speak about __domain adaptation__ AND task adaptation in case of transfer learning, we restrict ourselves to the former, so where the data is different, the task itself, in the simplest case forecasting is the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaining traction\n",
    "\n",
    "In their work [Transfer Learning With Time Series Data A Systematic Mapping Study](https://www.researchgate.net/publication/356945141_Transfer_Learning_With_Time_Series_Data_A_Systematic_Mapping_Study) the authors collect over 200 papers that talk about transfer learning in this field up until January 2021 (hence the funny data at the last bar).\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1vMAIoeBCoXNzaeuqgr-rl7wnQvsaNUjh\" width=45%>\n",
    "\n",
    "It is visible, that this field is gaining considerable traction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, in case of a more fine grained categorization of tasks the authors find, that time series classification dominates, maybe pointing toward the difficulty or (more likely) underutilization of the transfer learning approach to forecasting problems.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1dGRNVt1ab22VtB0ynh1jI9ny-_nV-IJV\" width=45%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges in time series transfer learning\n",
    "\n",
    "### 1. What hierarchy?\n",
    "\n",
    "As [this](https://towardsdatascience.com/transfer-learning-for-time-series-forecasting-51f023bc159c) wonderful article of Isaac Godfried argues, __what features to transfer__, or more specificly __what feature hierarchy to learn__ is not a simple task in case of time series. Or as the author puts it:\n",
    "\n",
    "\"In computer vision transfer learning generally works as the model learns in a hierarchical fashion; ...  in NLP ...  The transformer architecture in particular functioned well for transfer learning.  with time series it is harder to find a useful hierarchy or set of intermediate representations that generalize across to different problems. __We do have certain components that people traditionally decompose time series into such as seasonality, trend and remainder. However, developing a model that effectively learns intermediate decoupled representations of these remains elusive.__ The authors of “Reconstruction and Regression Loss for Time-Series Transfer Learning” explore creating a specialized loss function that helps to facilitate positive transfer through a decoupling process.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our view, this kind of decomposition - the natural hierarchy for time series features - is a promising avenue to go, and might hint at the application of [NBEATS](https://arxiv.org/abs/1905.10437) like models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidenote: different magnitudes\n",
    "\n",
    "A subproblem of the input differences arises from the fact, that the numeric magnitudes of timeseries differ. To circumvent this limitation, one proposal is to re-cast the original regression problem to an __ordinal regression__ task, where all the timeseries are discretized with an adaptive discretization into a fixed number of \"bins\", thus basically reducing the problem to predicting the next \"bin\" or by analogy \"word\" - if we follow the intuition of the authors pointing out the parallels with NLP:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1tnmY_15y1Gn4Elo35-mZiBcchwGMDuwM\" width=45%>\n",
    "\n",
    "Source: [Zero-shot and few-shot time series forecasting with ordinal regression recurrent neural networks](https://www.esann.org/sites/default/files/proceedings/2020/ES2020-71.pdf)\n",
    "\n",
    "Though the authors stick to an LSTM based seq2seq approach, nothing prevents us from aplpying more recent models the same way, so this can be an interesting avenue for further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What inputs?\n",
    "\n",
    "Moreover, the Godfried points out:\n",
    "\n",
    "\"A second challenge with multivariate time series forecasting is that many times the problems have a different number of feature time series. \n",
    "\n",
    "In our experiments we have generally found using a model specific initial “embedding_layer” helpful then having transferable middle layers.\"\n",
    "\n",
    "So some care has to be taken in case os multivariate time series, but this does not seem to be a showstopper in itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What source to transfer from?\n",
    "\n",
    "Even in case of \"classical\" domains of machine learning it is a widesprad observation, that the similarity between source and target datasets considered for transfer learning constrain the possible amount of performance gain: __the more closely source and target are related, the more gains can be had__.\n",
    "    \n",
    "It is absolutely not unreasonable to assume that this is a case in time series data also. \n",
    "\n",
    "None the less, the diversity of time series datasets can be considerable, measuring their relatedness is not a trivial task. Though the most proper way to measure similarity between time series data presupposes some kind of description / modeling already, so this can be a kind of vicious circle: if we understand a dataset, we can perfectly discover it's relations to other ones. Not wanting to make this to an infinite regress, the authors of the paper [Implementing transfer learning across different datasets for time\n",
    "series forecasting](https://www.sciencedirect.com/science/article/abs/pii/S0031320320304209) suggest, that __more simple alignement and distance measures can be used to pre-select relevant time series for modeling.__ Namely: they propose to do [Dynamic Time Warping](https://en.wikipedia.org/wiki/Dynamic_time_warping) to align series, and then use [Jenssen-Shannon divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence) to calculate elatedness and choose sources for transfer. \n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1vwQgvvBTFv7IEW0ltGcz_K3lSjibdU41\" width=55%>\n",
    "\n",
    "#### Sidenote of interest: \n",
    "\n",
    "In the aformentioned work the authors also utilize causal convnets as basis learners, as well as a joint training and representation alignment loss based approach to carry out the transfer. The second best behaving model is transfer learned TCN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A more elaborate approach to \"pairing\"\n",
    "\n",
    "As a more subtle observation, one could argue, that the mere \"surface level\" similarity of two time series (eg. their \"time domain\" distance based on some metric) is the most appropriate tool to judge the usefulness of a given source dataset in the transfer learning scenario in order to achiece the highest performance on the target dataset.\n",
    "\n",
    "Some recent works, like [\"A relationship-aligned transfer learning algorithm for time series forecasting\"](https://www.sciencedirect.com/science/article/abs/pii/S0020025522001104) set out to tackle this uestion by searching for alignment / choice of suitable source time series __in the space of learned representations__.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Fjb2cBcJHWz65xRCtYXKCnRqoN0ivvrZ\" width=65%>\n",
    "\n",
    "Let us go through the steps laid out in the paper:\n",
    "\n",
    "__STEP 1.__\n",
    "\n",
    "\"Specifically, during the design and construction of the proposed RATL algorithm, \n",
    "\n",
    "__we firstly design 'a representation learning module.__\n",
    "\n",
    "It is viewed as the encoder and is utilized to explore the underlying features of time series. In the source dataset \n",
    "selection phase, in order to measure whether a potential source dataset is in favor of the target task, an encoder trained based on this dataset is applied to the target task to produce the informative representations. Then, a simple linear layer is added to perform the prediction on basis of these representations. ... the prediction performance of the linear layer can also, to some extent, reflect the effectiveness of the representation learning \n",
    "module. The better the forecasting performance is, the more suitable the encoder will be to the target task.\"\n",
    "\n",
    "\n",
    "__STEP 2.__\n",
    "\n",
    "After the choice of the most suitable sources, a separate step for representation learning is initialized to get to the appropriate representation for the target dataset.\n",
    "\n",
    "__STEP 3. and 4.__\n",
    "\n",
    "Relationship aligned learning phase, the encoder module if frozen, and a triplet similarity based learning procedure is initialized to learn an alignment transformation between the source and target encoders's representations.\n",
    "\n",
    "__STEP 5.__\n",
    "\n",
    "Regression aligned learning phase one more layer of finetuning is acrried out to maximize the regression performance over the previous representations with respect to forecasting performance.\n",
    "\n",
    "__STEP 6.__\n",
    "\n",
    "Final target prediction is carried out.\n",
    "\n",
    "\n",
    "Some results:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1qWBeq2-2Qe1PfVWVGOtaylP0Ji1Pkays\" width=65%>\n",
    "\n",
    "##### Observation\n",
    "\n",
    "A really delicate and elaborate methodology has to be utilized to achieve an at best modest increase in predictive performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...Some promising results in general\n",
    "\n",
    "To quantify the potential of transfer learning in general, recently people started to more sytematically investigate the possible performance gains of transfer learning in time series forecasting domain, eg. in the work [Performance of Deep Learning models with transfer learning for multiple-step-ahead forecasts in monthly time series](https://arxiv.org/abs/2203.11196).\n",
    "\n",
    "The authors find, that transfer learning enhanced neural models beat non-neural baselines as well as offer advantages against only target trained neural models:\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1XS_-PmjmL9dF1hetYpa9_PXejLhY_9c1\" width=55%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting, that this survey only includes \"regular\" convnets, LSTM-s and Temporal Convolution Networks, but no hybrid models, transformers or NBEATS derivatives.\n",
    "\n",
    "None the less __there seems to be potential in time series transfer learning__, that is worth taking a look at!\n",
    "\n",
    "Thus said, __one has the impression, that we are still waiting for a big breakthrough to come.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilogue\n",
    "\n",
    "With all the innovation going on, this area of modeling is far from \"settled\". \n",
    "\n",
    "There is still considerable amount of well founded scepticism with regard to the dominance of deep learning techniques in the time series field, like in:\n",
    "\n",
    "[Do we really need deep learning for TS](https://arxiv.org/abs/2101.0211)\n",
    "\n",
    "It is thus still a question - albeit with some [positive results](https://arxiv.org/abs/2002.02887) if the \"zero shot learning\" paradigm, that came to dominate NLP will come to the time series domain.\n",
    "\n",
    "Keep an eye out for disruptive changes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "Good intro to some recent tools in time series modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/ng8i5KPf6d0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fdfc042b790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.YouTubeVideo(id=\"ng8i5KPf6d0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also very well worth studying:\n",
    "- [Time Series Analysis and Modeling to Forecast: a Survey](https://arxiv.org/abs/2104.00164)\n",
    "- [Transfer Learning With Time Series Data: A Systematic Mapping Study](https://www.researchgate.net/publication/356945141_Transfer_Learning_With_Time_Series_Data_A_Systematic_Mapping_Study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
